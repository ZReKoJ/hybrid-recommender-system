{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLNqYBgmGIyf"
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9hzzVAc5GBA_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy\n",
    "import json\n",
    "import nltk\n",
    "import math\n",
    "import re\n",
    "import threading\n",
    "import copy\n",
    "import requests \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize.regexp import (WordPunctTokenizer,wordpunct_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vH15YyQGM1I"
   },
   "source": [
    "Links for the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Kj91r1mXGRPD"
   },
   "outputs": [],
   "source": [
    "url_links = 'https://zrekoj.github.io/hybrid-recommender-system/dataset/links.csv'\n",
    "url_movies = 'https://zrekoj.github.io/hybrid-recommender-system/dataset/movies.csv'\n",
    "url_ratings = 'https://zrekoj.github.io/hybrid-recommender-system/dataset/ratings.csv'\n",
    "url_tags = 'https://zrekoj.github.io/hybrid-recommender-system/dataset/tags.csv'\n",
    "url_genres = 'https://zrekoj.github.io/hybrid-recommender-system/dataset/user_genre.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7uqFvueudeU"
   },
   "source": [
    "Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "JUqBO0kkucLC"
   },
   "outputs": [],
   "source": [
    "ds_links = pd.read_csv(url_links, dtype = str)\n",
    "ds_movies = pd.read_csv(url_movies, dtype = str)\n",
    "ds_ratings = pd.read_csv(url_ratings)\n",
    "ds_tags = pd.read_csv(url_tags, dtype = str)\n",
    "ds_user_genres = pd.read_json(url_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "uxrT24702OZK"
   },
   "outputs": [],
   "source": [
    "list_movies_id = list(ds_movies['movieId'].unique())\n",
    "list_title_id = ds_movies['title'].tolist()\n",
    "list_users_id = list(ds_ratings['userId'].unique())\n",
    "list_movies_imdbid = ds_links['imdbId'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uCHdeaAxoy5i"
   },
   "source": [
    "Input ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 572
    },
    "id": "O_MY4EUno1II",
    "outputId": "2507215a-d421-4bff-dae7-7bdce5d22934"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"\\nmovie_ids=[]\\nratings=[]\\n\\nfor i in range(10):\\n  index=random.randint(0,len(list_movies_id)-1)\\n  while list_movies_id[index] in movie_ids:\\n    index=random.randint(0,len(list_movies_id)-1)\\n  rating = float(input('Rate the movie '+str(list_title_id[index])+' from 0.5 to 5.0 or say 0.0 if you haven't seen it :'))\\n  movie_ids.append(list_movies_id[index])\\n  ratings.append(rating)\\nprint(movie_ids)\\nprint(ratings)\\n\""
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "'''\n",
    "movie_ids=[]\n",
    "ratings=[]\n",
    "\n",
    "for i in range(10):\n",
    "  index=random.randint(0,len(list_movies_id)-1)\n",
    "  while list_movies_id[index] in movie_ids:\n",
    "    index=random.randint(0,len(list_movies_id)-1)\n",
    "  rating = float(input('Rate the movie '+str(list_title_id[index])+' from 0.5 to 5.0 or say 0.0 if you haven\\'t seen it :'))\n",
    "  movie_ids.append(list_movies_id[index])\n",
    "  ratings.append(rating)\n",
    "print(movie_ids)\n",
    "print(ratings)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfYUIC48Cta9"
   },
   "source": [
    "Collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zY9Fa_VcLVa"
   },
   "source": [
    "SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "szoO5K7IKg5e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(['Film-Noir', 'Animation', 'Musical', 'Children', 'Drama', 'War'], ['Comedy', 'Sci-Fi', 'Mystery', 'Thriller', 'Horror'])\n"
     ]
    }
   ],
   "source": [
    "def getGenresByUser(user_id, ds=ds_user_genres):\n",
    "  return ds[user_id]['like'], ds[user_id]['dislike']\n",
    "\n",
    "print(getGenresByUser(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "KRrF5bPD_bZs"
   },
   "outputs": [],
   "source": [
    "#hyperparams\n",
    "\n",
    "test_ratio = 0.2 #fraction of data to be used as test set.\n",
    "no_of_features = [8,10,12,14,17,20] # to test the performance over a different number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "HVL4pD2A9zIu"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'test_ratio' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-eecff6b8ae41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m   \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds_ratings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mds_ratings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'userId'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m   \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m   \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_ratio\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m   \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'timestamp'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_ratio' is not defined"
     ]
    }
   ],
   "source": [
    "ds_ratings['userId'] = ds_ratings['userId'].astype('str')\n",
    "ds_ratings['movieId'] = ds_ratings['movieId'].astype('str')\n",
    "\n",
    "users = ds_ratings['userId'].unique() #list of all users\n",
    "movies = ds_ratings['movieId'].unique() #list of all movies\n",
    "\n",
    "test = pd.DataFrame(columns=ds_ratings.columns)\n",
    "train = pd.DataFrame(columns=ds_ratings.columns)\n",
    "\n",
    "for u in users:\n",
    "  temp = ds_ratings[ds_ratings['userId'] == u]\n",
    "  n = len(temp)\n",
    "  test_size = int(test_ratio*n)\n",
    "\n",
    "  temp = temp.sort_values('timestamp').reset_index()\n",
    "  temp.drop('index', axis=1, inplace=True)\n",
    "\n",
    "  dummy_test = temp.loc[n-1-test_size :]\n",
    "  dummy_train = temp.loc[: n-2-test_size]\n",
    "    \n",
    "  test = pd.concat([test, dummy_test])\n",
    "  train = pd.concat([train, dummy_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "GvRLP6__-98r"
   },
   "outputs": [],
   "source": [
    "from scipy.linalg import sqrtm\n",
    "\n",
    "def create_user_item_matrix(data, formatizer = {'user':0, 'item': 1, 'value': 2}):\n",
    "    itemField = formatizer['item']\n",
    "    userField = formatizer['user']\n",
    "    valueField = formatizer['value']\n",
    "\n",
    "    \n",
    "    userList = data.iloc[:,userField].tolist()\n",
    "    itemList = data.iloc[:,itemField].tolist()\n",
    "    valueList = data.iloc[:,valueField].tolist()\n",
    "\n",
    "    users = list(set(data.iloc[:,userField]))\n",
    "    items = list(set(data.iloc[:,itemField]))\n",
    "\n",
    "    users_index = {users[i]: i for i in range(len(users))}\n",
    "\n",
    "    pd_dict = {item: [np.nan for i in range(len(users))] for item in items}\n",
    "\n",
    "    for i in range(0,len(data)):\n",
    "      item = itemList[i]\n",
    "      user = userList[i]\n",
    "      value = valueList[i]\n",
    "\n",
    "      pd_dict[item][users_index[user]] = value\n",
    "    \n",
    "    X = pd.DataFrame(pd_dict)\n",
    "    X.index = users\n",
    "\n",
    "    itemcols = list(X.columns)\n",
    "    items_index = {itemcols[i]: i for i in range(len(itemcols))}\n",
    "\n",
    "    # users_index gives us a mapping of user_id to index of user\n",
    "    # items_index provides the same for items\n",
    "\n",
    "    return X, users_index, items_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "tr-QPs9A_K6a"
   },
   "outputs": [],
   "source": [
    "def svd(train, k):\n",
    "    utilMat = np.array(train)\n",
    "\n",
    "    # the nan or unavailable entries are masked\n",
    "    mask = np.isnan(utilMat)\n",
    "    masked_arr = np.ma.masked_array(utilMat, mask)\n",
    "\n",
    "    item_means = np.mean(masked_arr, axis=0)\n",
    "\n",
    "    # nan entries will replaced by the average rating for each item\n",
    "    utilMat = masked_arr.filled(item_means)\n",
    "    x = np.tile(item_means, (utilMat.shape[0],1))\n",
    "\n",
    "    # we remove the per item average from all entries.\n",
    "    # the above mentioned nan entries will be essentially zero now\n",
    "    utilMat = utilMat - x\n",
    "\n",
    "    # The magic happens here. U and V are user and item features\n",
    "    U, s, V=np.linalg.svd(utilMat, full_matrices=False)\n",
    "    s=np.diag(s)\n",
    "\n",
    "    # we take only the k most significant features\n",
    "    s=s[0:k,0:k]\n",
    "    U=U[:,0:k]\n",
    "    V=V[0:k,:]\n",
    "\n",
    "    s_root=sqrtm(s)\n",
    "    Usk=np.dot(U,s_root)\n",
    "    skV=np.dot(s_root,V)\n",
    "    UsV = np.dot(Usk, skV)\n",
    "    UsV = UsV + x\n",
    "    return UsV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "3sG_ANug_Sj_"
   },
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    x = true - pred\n",
    "    return sum([xi*xi for xi in x])/len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "zalPgxeI_Wh-"
   },
   "outputs": [],
   "source": [
    "uiMat, users_index, items_index = create_user_item_matrix(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ixHyBKd3_q5f",
    "outputId": "f123df74-c648-4f27-ff56-5e9628d24459"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.003787809237221\n",
      "1.0036410576245889\n",
      "1.0047280968304313\n",
      "1.0053854409715484\n",
      "1.0046710025637096\n",
      "1.005656722964721\n"
     ]
    }
   ],
   "source": [
    "#svd evaluation\n",
    "for f in no_of_features:\n",
    "  svdout = svd(uiMat, k=f)\n",
    "  pred = [] #to store the predicted ratings\n",
    "  for _,row in test.iterrows():\n",
    "    user = row['userId']\n",
    "    item = row['movieId']\n",
    "    u_index = users_index[user]\n",
    "    \n",
    "    if item in items_index:\n",
    "      i_index = items_index[item]\n",
    "      pred_rating = svdout[u_index, i_index]\n",
    "    else:\n",
    "      pred_rating = np.mean(svdout[u_index, :])\n",
    "    pred.append(pred_rating)\n",
    "  print(rmse(test['rating'], pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "yYdr_ohfTZwz"
   },
   "outputs": [],
   "source": [
    "def filter(u_id, user_genres = ds_user_genres, item_genres = ds_movies[\"genres\"]):\n",
    "  u_likes = user_genres[u_id][\"like\"]\n",
    "  u_detest = user_genres[u_id][\"dislike\"]\n",
    "\n",
    "  useritemMat, users_index, items_index = create_user_item_matrix(ds_ratings)\n",
    "  svdout = svd(useritemMat, k=12)\n",
    "  user_pos = users_index[str(u_id)]\n",
    "  result = []\n",
    "  for i in range(len(svdout[user_pos])):\n",
    "\n",
    "    if str(i) in items_index:\n",
    "      i_id = items_index[str(i)]\n",
    "      i_genre = item_genres[i_id].split(sep=\"|\")\n",
    "\n",
    "      checkDislike =  any(item in i_genre for item in u_detest)\n",
    "      if checkDislike is False:\n",
    "        new_rate = svdout[user_pos][i]\n",
    "\n",
    "        checkLike =  any(item in i_genre for item in u_likes)\n",
    "        if checkLike is True and new_rate < 5.0:\n",
    "          new_rate = new_rate + new_rate * .3\n",
    "          if new_rate > 5.0:\n",
    "            new_rate = 5.0\n",
    "        result.append([ds_movies['movieId'][i_id], ds_movies[\"title\"][i_id], new_rate])\n",
    " \n",
    "  return sorted(result, key=lambda item: item[2], reverse=True)[:20]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ilIi5vZJbgd6"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['5611', 'Four Feathers, The (2002)', 5.0],\n",
       " ['102088', 'Grandmaster, The (Yi dai zong shi) (2013)', 5.0],\n",
       " ['2745', 'Mission, The (1986)', 5.0],\n",
       " ['4292', 'Norma Rae (1979)', 5.0],\n",
       " ['7056', 'Public Enemy, The (1931)', 5.0],\n",
       " ['1933', 'Life of Emile Zola, The (1937)', 5.0],\n",
       " ['159811', 'The Bremen Town Musicians (1969)', 5.0],\n",
       " ['172583', 'Investigation Held by Kolobki (1986)', 5.0],\n",
       " ['26176', 'Titicut Follies (1967)', 5.0],\n",
       " ['5965', 'Duellists, The (1977)', 5.0],\n",
       " ['6668', 'Road Home, The (Wo de fu qin mu qin) (1999)', 5.0],\n",
       " ['484', 'Lassie (1994)', 5.0],\n",
       " ['7820', 'Virgin Spring, The (JungfrukÃ¤llan) (1960)', 5.0],\n",
       " ['954', 'Mr. Smith Goes to Washington (1939)', 5.0],\n",
       " ['1170', 'Best of the Best 3: No Turning Back (1995)', 5.0],\n",
       " ['3011', \"They Shoot Horses, Don't They? (1969)\", 5.0],\n",
       " ['3089',\n",
       "  'Bicycle Thieves (a.k.a. The Bicycle Thief) (a.k.a. The Bicycle Thieves) (Ladri di biciclette) (1948)',\n",
       "  5.0],\n",
       " ['563', 'Germinal (1993)', 5.0],\n",
       " ['43376',\n",
       "  'Sophie Scholl: The Final Days (Sophie Scholl - Die letzten Tage) (2005)',\n",
       "  5.0],\n",
       " ['95175', 'Front of the Class (2008)', 5.0]]"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "filter(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7wSplTSCq7_"
   },
   "source": [
    "**Content-based**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "INdMx6n9Cs_P"
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(u, v):\n",
    "    return np.dot(u, np.transpose(v)) / (np.linalg.norm(u) * np.linalg.norm(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJ4w4ThMbyiK"
   },
   "source": [
    "Calculate TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "jdp1gOGyb3kB"
   },
   "outputs": [],
   "source": [
    " def computeTFIDF(user_frequence_dict):\n",
    "        copied = copy.deepcopy(user_frequence_dict)\n",
    "        total_movies = len(copied)\n",
    "        total_word_movies_count = {}\n",
    "\n",
    "        for frequency in copied.values():\n",
    "            for word in frequency:\n",
    "                total_word_movies_count[word] = total_word_movies_count.get(word, 0) + 1\n",
    "\n",
    "        for frequency in copied.values():\n",
    "            total_words_count = len(frequency)\n",
    "            for word in frequency:\n",
    "                #                TF                                 IDF\n",
    "                frequency[word] = (frequency[word] / total_words_count) * (math.log(1 + (total_movies / total_word_movies_count[word])))\n",
    "        return copied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MxnJAY9xiQA2"
   },
   "source": [
    "Content-Based application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1094249 0.07950933188193429\n",
      "0119577 0.03278998241794748\n",
      "0146838 0.06455013019546887\n",
      "0089385 0.05815471304629225\n",
      "0304229 0.0855014873973386\n",
      "0114007 0.055105358151090536\n",
      "0114916 0.0595944109930006\n",
      "0102798 0.17307629401493463\n",
      "0041594 0.07057003329608129\n",
      "0199129 0.12967858576323765\n",
      "1510938 0.07786330345947903\n",
      "0092545 0.07533071561265854\n",
      "0244316 0.05788941191858764\n",
      "0104779 0.05918078229511197\n",
      "0294357 0.12049458341852526\n",
      "0113824 0.125902194245651\n",
      "0118819 0.08952145915043483\n",
      "0112342 0.09077668893012354\n",
      "0038499 0.06793468001299897\n",
      "2381991 0.06856206481457755\n",
      "[['0102798', 0.17307629401493463], ['0199129', 0.12967858576323765], ['0113824', 0.125902194245651], ['0294357', 0.12049458341852526], ['0112342', 0.09077668893012354], ['0118819', 0.08952145915043483], ['0304229', 0.0855014873973386], ['1094249', 0.07950933188193429], ['1510938', 0.07786330345947903], ['0092545', 0.07533071561265854], ['0041594', 0.07057003329608129], ['2381991', 0.06856206481457755], ['0038499', 0.06793468001299897], ['0146838', 0.06455013019546887], ['0114916', 0.0595944109930006], ['0104779', 0.05918078229511197], ['0089385', 0.05815471304629225], ['0244316', 0.05788941191858764], ['0114007', 0.055105358151090536], ['0119577', 0.03278998241794748]]\n"
     ]
    }
   ],
   "source": [
    "def content_based(user_id, hybrid=True):\n",
    "\n",
    "    movie_similarities=[]\n",
    "\n",
    "    #Get imbdIds of user movies\n",
    "    user_movies = list(\n",
    "        map(\n",
    "            lambda movie_id : str(ds_links.loc[ds_links['movieId'] == str(movie_id), 'imdbId'].values[0]), \n",
    "            ds_ratings.loc[ds_ratings['userId'] == str(user_id), 'movieId'].tolist()\n",
    "        )\n",
    "    )\n",
    "\n",
    "    collaborative_filtering_result = filter(user_id)\n",
    "\n",
    "\n",
    "    movies=[]\n",
    "\n",
    "    #If we are using content-based as part of the hybrid filter, it uses the results of the collaborative filtering\n",
    "    #Otherwise it uses all movies\n",
    "    if(hybrid):\n",
    "        movies = list(\n",
    "            map(\n",
    "                lambda result : ds_links.loc[ds_links['movieId'] == str(result[0]), 'imdbId'].values[0], \n",
    "                collaborative_filtering_result\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        movies=[str(movie_id) for movie_id in list_movies_imdbid if movie_id not in user_movies]\n",
    "\n",
    "    response = requests.get('https://zrekoj.github.io/hybrid-recommender-system/user_frequency/'+ str(user_id)+'.json') \n",
    "    user_frequence_dict = response.json()\n",
    "\n",
    "    for movie in movies:\n",
    "        MaxSim = 0\n",
    "\n",
    "        movie_frequence_dict = requests.get('https://zrekoj.github.io/hybrid-recommender-system/frequency/'+ str(movie)+'.json').json() \n",
    "        user_frequence_dict[str(movie)] = movie_frequence_dict\n",
    "        TFIDF = computeTFIDF(user_frequence_dict)\n",
    "        user_frequence_dict.pop(str(movie), None)\n",
    "\n",
    "        no_exist_string = \"***###***\"\n",
    "        \n",
    "        TFIDF_highest = TFIDF[str(movie)]\n",
    "        for user_movie in user_movies:\n",
    "            TFIDF_user =  TFIDF[str(user_movie)]\n",
    "            \n",
    "            TFIDF_highest_keys = TFIDF_highest.keys()\n",
    "            TFIDF_user_keys = TFIDF_user.keys()\n",
    "            \n",
    "            coincidence = list(set(TFIDF_highest_keys) & set(TFIDF_user_keys))\n",
    "            TFIDF_highest_values_diff = list(set(TFIDF_highest_keys) - set(TFIDF_user_keys))\n",
    "            TFIDF_user_values_diff = list(set(TFIDF_user_keys) - set(TFIDF_highest_keys))\n",
    "            \n",
    "            TFIDF_highest_values = coincidence + TFIDF_highest_values_diff + ([no_exist_string] * len(TFIDF_user_values_diff))\n",
    "            TFIDF_user_values = coincidence + ([no_exist_string] * len(TFIDF_highest_values_diff)) + TFIDF_user_values_diff\n",
    "            \n",
    "            TFIDF_highest_values = list(\n",
    "                map(\n",
    "                    lambda value : TFIDF_highest[value] if value != no_exist_string else 0,\n",
    "                    TFIDF_highest_values\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            TFIDF_user_values = list(\n",
    "                map(\n",
    "                    lambda value : TFIDF_user[value] if value != no_exist_string else 0,\n",
    "                    TFIDF_user_values\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            similarity = cosine_similarity(TFIDF_highest_values, TFIDF_user_values)        \n",
    "\n",
    "            if(similarity > MaxSim):\n",
    "                MaxSim = similarity\n",
    "                \n",
    "        movie_similarities.append([movie, MaxSim])\n",
    "        \n",
    "\n",
    "    return sorted(movie_similarities, key=lambda item: item[1], reverse=True)\n",
    "\n",
    "print(content_based(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h66pQrMvx3oC"
   },
   "source": [
    "Fuzzy Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "id": "AooHYk2M_pY4",
    "outputId": "53624136-87cb-487c-9607-a361ea979263"
   },
   "outputs": [],
   "source": [
    "import skfuzzy as fuzz\n",
    "from skfuzzy import control as ctrl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'ds_ratings' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-c3b2633737c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Not normalized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0muser_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds_ratings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0muser_ratings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds_ratings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mds_ratings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'userId'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0maverage_rating\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_ratings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rating'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ds_ratings' is not defined"
     ]
    }
   ],
   "source": [
    "#Not normalized\n",
    "user_id=1\n",
    "print(ds_ratings.head())\n",
    "user_ratings = ds_ratings[ds_ratings['userId']==str(user_id)]\n",
    "average_rating=np.average(user_ratings['rating'])\n",
    "total_rating=len(user_ratings['rating'])\n",
    "content_based_result=[['0102798', 0.17307629401493463], ['0199129', 0.12967858576323765], ['0113824', 0.125902194245651], ['0294357', 0.12049458341852526], ['0112342', 0.09077668893012354], ['0118819', 0.08952145915043483], ['0304229', 0.0855014873973386], ['1094249', 0.07950933188193429], ['1510938', 0.07786330345947903], ['0092545', 0.07533071561265854], ['0041594', 0.07057003329608129], ['2381991', 0.06856206481457755], ['0038499', 0.06793468001299897], ['0146838', 0.06455013019546887], ['0114916', 0.0595944109930006], ['0104779', 0.05918078229511197], ['0089385', 0.05815471304629225], ['0244316', 0.05788941191858764], ['0114007', 0.055105358151090536], ['0119577', 0.03278998241794748]]\n",
    "#content_based_result=content_based(user_id)\n",
    "similarity=content_based_result[0][1]\n",
    "print(user_ratings['rating'])\n",
    "print(average)\n",
    "print(total_rating)\n",
    "#Generate variables\n",
    "inp1 = np.arange(0, 5.5, 0.5)\n",
    "inp2 = np.arange(0, 351, 1)\n",
    "inp3 = np.arange(0, 1.05, 0.05)\n",
    "importance = np.arange(0, 1.05, 0.05)\n",
    "\n",
    "#Generate fuzzy membership functions\n",
    "inp1_low = fuzz.trimf(inp1, [0, 0, 2.5])\n",
    "inp1_medium = fuzz.trimf(inp1, [0, 2.5, 5])\n",
    "inp1_high = fuzz.trimf(inp1, [2.5, 5, 5])\n",
    "inp2_few = fuzz.trimf(inp2, [0, 0, 175])\n",
    "inp2_much = fuzz.trimf(inp2, [0, 175, 350])\n",
    "inp2_very_much = fuzz.trimf(inp2, [175, 350, 350])\n",
    "inp3_low = fuzz.trimf(inp3, [0, 0, 0.15])\n",
    "inp3_very_high = fuzz.trimf(inp3, [0.1, 1, 1])\n",
    "importance_very_low = fuzz.trimf(importance, [0, 0, 0.25])\n",
    "importance_low = fuzz.trimf(importance, [0, 0.25, 0.5])\n",
    "importance_medium = fuzz.trimf(importance, [0.25, 0.5, 0.75])\n",
    "importance_high = fuzz.trimf(importance, [0.5, 0.75, 1])\n",
    "importance_very_high = fuzz.trimf(importance, [0, 1, 1])\n",
    "\n",
    "#Visualize fuzzy membership functions\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(nrows=3, figsize=(8, 9))\n",
    "ax0.plot(inp1, inp1_low, 'b', linewidth=1.5, label='Low')\n",
    "ax0.plot(inp1, inp1_medium, 'g', linewidth=1.5, label='Medium')\n",
    "ax0.plot(inp1, inp1_high, 'r', linewidth=1.5, label='High')\n",
    "ax0.set_title('Average rating')\n",
    "ax0.legend()\n",
    "\n",
    "ax1.plot(inp2, inp2_few, 'b', linewidth=1.5, label='Few')\n",
    "ax1.plot(inp2, inp2_much, 'g', linewidth=1.5, label='Much')\n",
    "ax1.plot(inp2, inp2_very_much, 'r', linewidth=1.5, label='Very much')\n",
    "ax1.set_title('Total ratings')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(inp3, inp3_low, 'b', linewidth=1.5, label='Low')\n",
    "ax2.plot(inp3, inp3_very_high, 'g', linewidth=1.5, label='Very high')\n",
    "ax2.set_title('Similarity')\n",
    "ax2.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  userId movieId  rating  timestamp\n0      1       1     4.0  964982703\n1      1       3     4.0  964981247\n2      1       6     4.0  964982224\n3      1      47     5.0  964983815\n4      1      50     5.0  964982931\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'content_based' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-814d4c8b902e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0maverage_rating\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_ratings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rating'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtotal_rating\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_ratings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rating'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m350\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mcontent_based_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontent_based\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontent_based_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_ratings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rating'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'content_based' is not defined"
     ]
    }
   ],
   "source": [
    "#Normalized\n",
    "user_id=1\n",
    "print(ds_ratings.head())\n",
    "user_ratings = ds_ratings[ds_ratings['userId']==str(user_id)]\n",
    "average_rating=np.average(user_ratings['rating'])/5\n",
    "total_rating=len(user_ratings['rating'])/350\n",
    "content_based_result=content_based(user_id)\n",
    "similarity=content_based_result[0][1]\n",
    "print(user_ratings['rating'])\n",
    "print(average_rating)\n",
    "print(total_rating)\n",
    "#Generate variables\n",
    "inp1 = np.arange(0, 1.01, 0.01)\n",
    "inp2 = np.arange(0, 1.01, 0.01)\n",
    "inp3 = np.arange(0, 1.01, 0.01)\n",
    "importance = np.arange(0, 1.01, 0.01)\n",
    "\n",
    "#Generate fuzzy membership functions\n",
    "inp1_low = fuzz.trimf(inp1, [0, 0, 0.5])\n",
    "inp1_medium = fuzz.trimf(inp1, [0, 0.5, 1])\n",
    "inp1_high = fuzz.trimf(inp1, [0.5, 1, 1])\n",
    "inp2_few = fuzz.trimf(inp2, [0, 0, 0.3])\n",
    "inp2_medium = fuzz.trimf(inp2, [0.2, 0.4, 0.5])\n",
    "inp2_much = fuzz.trimf(inp2, [0, 0.5, 1])\n",
    "inp2_very_much = fuzz.trimf(inp2, [0.5, 1, 1])\n",
    "inp3_very_low = fuzz.trimf(inp3, [0, 0, 0.06])\n",
    "inp3_low = fuzz.trimf(inp3, [0.05, 0.06, 0.07])\n",
    "inp3_medium = fuzz.trimf(inp3, [0.06, 0.07, 0.08])\n",
    "inp3_high = fuzz.trimf(inp3, [0.07, 0.1, 0.13])\n",
    "inp3_very_high = fuzz.trimf(inp3, [0.1, 1, 1])\n",
    "                            \n",
    "importance_very_low = fuzz.trimf(inp1, [0, 0, 0.25])\n",
    "importance_low = fuzz.trimf(inp1, [0, 0.25, 0.5])\n",
    "importance_medium = fuzz.trimf(inp1, [0.25, 0.5, 0.75])\n",
    "importance_high = fuzz.trimf(inp1, [0.5, 0.75, 1])\n",
    "importance_very_high = fuzz.trimf(inp1, [0.75, 1, 1])\n",
    "\n",
    "#Visualize fuzzy membership functions\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(nrows=3, figsize=(8, 9))\n",
    "ax0.plot(inp1, inp1_low, 'b', linewidth=1.5, label='Low')\n",
    "ax0.plot(inp1, inp1_medium, 'g', linewidth=1.5, label='Medium')\n",
    "ax0.plot(inp1, inp1_high, 'r', linewidth=1.5, label='High')\n",
    "ax0.set_title('Average rating')\n",
    "ax0.legend()\n",
    "\n",
    "ax1.plot(inp2, inp2_few, 'b', linewidth=1.5, label='Few')\n",
    "ax1.plot(inp2, inp2_much, 'g', linewidth=1.5, label='Much')\n",
    "ax1.plot(inp2, inp2_very_much, 'r', linewidth=1.5, label='Very much')\n",
    "ax1.set_title('Total ratings')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(inp3, inp3_low, 'b', linewidth=1.5, label='Low')\n",
    "ax2.plot(inp3, inp3_very_high, 'g', linewidth=1.5, label='Very high')\n",
    "ax2.set_title('Similarity')\n",
    "ax2.legend()\n",
    "\n",
    "\n",
    "#Apply rules\n",
    "inp1_lo = fuzz.interp_membership(inp1, inp1_low, average_rating)\n",
    "inp1_md = fuzz.interp_membership(inp1, inp1_medium, average_rating)\n",
    "inp1_hi = fuzz.interp_membership(inp1, inp1_high, average_rating)\n",
    "inp2_fe = fuzz.interp_membership(inp2, inp2_few, total_rating)\n",
    "inp2_md = fuzz.interp_membership(inp2, inp2_medium, total_rating)\n",
    "inp2_mu = fuzz.interp_membership(inp2, inp2_much, total_rating)\n",
    "inp2_vm = fuzz.interp_membership(inp2, inp2_very_much, total_rating)\n",
    "inp3_vl = fuzz.interp_membership(inp3, inp3_very_low, similarity)\n",
    "inp3_lo = fuzz.interp_membership(inp3, inp3_low, similarity)\n",
    "inp3_md = fuzz.interp_membership(inp3, inp3_medium, similarity)\n",
    "inp3_hi = fuzz.interp_membership(inp3, inp3_high, similarity)\n",
    "inp3_vh = fuzz.interp_membership(inp3, inp3_very_high, similarity)\n",
    "\n",
    "inp1_low_and_inp2_few = np.fmin(inp1_lo, inp2_fe)\n",
    "inp1_low_and_inp2_medium = np.fmin(inp1_lo, inp2_md)\n",
    "inp1_low_and_inp2_much = np.fmin(inp1_lo, inp2_mu)\n",
    "inp1_low_and_inp2_very_much = np.fmin(inp1_lo, inp2_vm)\n",
    "\n",
    "inp1_medium_and_inp2_few = np.fmin(inp1_md, inp2_fe)\n",
    "inp1_medium_and_inp2_medium = np.fmin(inp1_md, inp2_md)\n",
    "inp1_medium_and_inp2_much = np.fmin(inp1_md, inp2_mu)\n",
    "inp1_medium_and_inp2_very_much = np.fmin(inp1_md, inp2_vm)\n",
    "\n",
    "inp1_high_and_inp3_low = np.fmin(inp1_hi, inp3_lo)\n",
    "inp1_high_and_inp3_med = np.fmin(inp1_hi, inp3_md)\n",
    "inp1_high_and_inp3_high = np.fmin(inp1_hi, inp3_hi)\n",
    "inp1_high_and_inp3_very_high = np.fmin(inp1_hi, inp3_vh)\n",
    "\n",
    "rule_001_005_009 = np.fmin(inp1_low_and_inp2_few, inp3_lo)\n",
    "rule_002_006_010 = np.fmin(inp1_low_and_inp2_few, inp3_md)\n",
    "rule_003_007_011 = np.fmin(inp1_low_and_inp2_few, inp3_hi)\n",
    "rule_004_008_012 = np.fmin(inp1_low_and_inp2_few, inp3_vh)\n",
    "\n",
    "rule_013_017_021 = np.fmin(inp1_low_and_inp2_medium, inp3_lo)\n",
    "rule_014_018_022 = np.fmin(inp1_low_and_inp2_medium, inp3_md)\n",
    "rule_015_019_023 = np.fmin(inp1_low_and_inp2_medium, inp3_hi)\n",
    "rule_016_020_024 = np.fmin(inp1_low_and_inp2_medium, inp3_vh)\n",
    "\n",
    "rule_025_029_033 = np.fmin(inp1_low_and_inp2_much, inp3_lo)\n",
    "rule_026_030_034 = np.fmin(inp1_low_and_inp2_much, inp3_md)\n",
    "rule_027_031_035 = np.fmin(inp1_low_and_inp2_much, inp3_hi)\n",
    "rule_028_032_036 = np.fmin(inp1_low_and_inp2_much, inp3_vh)\n",
    "\n",
    "rule_037_041_045 = np.fmin(inp1_low_and_inp2_very_much, inp3_lo)\n",
    "rule_038_042_046 = np.fmin(inp1_low_and_inp2_very_much, inp3_md)\n",
    "rule_039_043_047 = np.fmin(inp1_low_and_inp2_very_much, inp3_hi)\n",
    "rule_040_044_048 = np.fmin(inp1_low_and_inp2_very_much, inp3_vh)\n",
    "\n",
    "rule_049_053_057 = np.fmin(inp1_medium_and_inp2_few, inp3_lo)\n",
    "rule_050_054_058 = np.fmin(inp1_medium_and_inp2_few, inp3_md)\n",
    "rule_051_055_059 = np.fmin(inp1_medium_and_inp2_few, inp3_hi)\n",
    "rule_052_056_060 = np.fmin(inp1_medium_and_inp2_few, inp3_vh)\n",
    "\n",
    "rule_061_065_069 = np.fmin(inp1_medium_and_inp2_medium, inp3_lo)\n",
    "rule_062_066_070 = np.fmin(inp1_medium_and_inp2_medium, inp3_md)\n",
    "rule_063_067_071 = np.fmin(inp1_medium_and_inp2_medium, inp3_hi)\n",
    "rule_064_068_072 = np.fmin(inp1_medium_and_inp2_medium, inp3_vh)\n",
    "\n",
    "rule_073_077_081 = np.fmin(inp1_medium_and_inp2_much, inp3_lo)\n",
    "rule_074_078_082 = np.fmin(inp1_medium_and_inp2_much, inp3_md)\n",
    "rule_075_079_083 = np.fmin(inp1_medium_and_inp2_much, inp3_hi)\n",
    "rule_076_080_084 = np.fmin(inp1_medium_and_inp2_much, inp3_vh)\n",
    "\n",
    "rule_085_089_093 = np.fmin(inp1_medium_and_inp2_very_much, inp3_lo)\n",
    "rule_086_090_094 = np.fmin(inp1_medium_and_inp2_very_much, inp3_md)\n",
    "rule_087_091_095 = np.fmin(inp1_medium_and_inp2_very_much, inp3_hi)\n",
    "rule_088_092_096 = np.fmin(inp1_medium_and_inp2_very_much, inp3_vh)\n",
    "\n",
    "rule_097_101_105 = np.fmin(inp1_high_and_inp3_low, inp2_fe)\n",
    "rule_098_102_106 = np.fmin(inp1_high_and_inp3_med, inp2_fe)\n",
    "rule_099_103_107 = np.fmin(inp1_high_and_inp3_high, inp2_fe)\n",
    "rule_100_104_108 = np.fmin(inp1_high_and_inp3_very_high, inp2_fe)\n",
    "\n",
    "rule_109_113_117 = np.fmin(inp1_high_and_inp3_low, inp2_md)\n",
    "rule_110_114_118 = np.fmin(inp1_high_and_inp3_med, inp2_md)\n",
    "rule_111_115_119 = np.fmin(inp1_high_and_inp3_high, inp2_md)\n",
    "rule_112_116_120 = np.fmin(inp1_high_and_inp3_very_high, inp2_md)\n",
    "\n",
    "rule_121_125_129 = np.fmin(inp1_high_and_inp3_low, inp2_mu)\n",
    "rule_122_126_130 = np.fmin(inp1_high_and_inp3_med, inp2_mu)\n",
    "rule_123_127_131 = np.fmin(inp1_high_and_inp3_high, inp2_mu)\n",
    "rule_124_128_132 = np.fmin(inp1_high_and_inp3_very_high, inp2_mu)\n",
    "\n",
    "rule_133_137_141 = np.fmin(inp1_high_and_inp3_low, inp2_vm)\n",
    "rule_134_138_142 = np.fmin(inp1_high_and_inp3_med, inp2_vm)\n",
    "rule_135_139_143 = np.fmin(inp1_high_and_inp3_high, inp2_vm)\n",
    "rule_136_140_144 = np.fmin(inp1_high_and_inp3_very_high, inp2_vm)\n",
    "\n",
    "\n",
    "very_low_rules=np.fmax(rule_001_005_009,\n",
    "                       np.fmax(rule_002_006_010,\n",
    "                               np.fmax(rule_003_007_011,\n",
    "                                       np.fmax(rule_004_008_012, \n",
    "                                               np.fmax(rule_013_017_021 ,\n",
    "                                                       np.fmax(rule_014_018_022,\n",
    "                                                               np.fmax(rule_015_019_023,\n",
    "                                                                       np.fmax(rule_016_020_024,\n",
    "                                                                              np.fmax(rule_025_029_033,\n",
    "                                                                                     np.fmax(rule_026_030_034,\n",
    "                                                                                            np.fmax(rule_027_031_035,\n",
    "                                                                                                   np.fmax(rule_028_032_036,\n",
    "                                                                                                          np.fmax(rule_037_041_045,\n",
    "                                                                                                                 np.fmax(rule_038_042_046,\n",
    "                                                                                                                        np.fmax(rule_039_043_047,\n",
    "                                                                                                                                np.fmax(rule_040_044_048,\n",
    "                                                                                                                                       np.fmax(rule_049_053_057 ,\n",
    "                                                                                                                                              np.fmax(rule_050_054_058 ,rule_051_055_059 ))))))))))))))))))\n",
    "#TODO\n",
    "low_rules=np.fmax(rule_004_008_012,\n",
    "np.fmax(rule_049_053_057,\n",
    "np.fmax(rule_050_054_058 ,\n",
    "np.fmax(rule_051_055_059 ,\n",
    "np.fmax(rule_052_056_060,\n",
    "np.fmax(rule_061_065_069 ,\n",
    "np.fmax(rule_062_066_070 ,\n",
    "np.fmax(rule_063_067_071,\n",
    "np.fmax(rule_064_068_072,\n",
    "np.fmax(rule_073_077_081 ,\n",
    "np.fmax(rule_074_078_082 ,\n",
    "np.fmax(rule_075_079_083,\n",
    "np.fmax(rule_085_089_093,\n",
    "np.fmax(rule_086_090_094,\n",
    "np.fmax(rule_097_101_105,rule_098_102_106)))))))))))))))\n",
    "\n",
    "medium_rules=np.fmax(rule_052_056_060,\n",
    "                     np.fmax(rule_062_066_070,\n",
    "                             np.fmax(rule_063_067_071,\n",
    "                                     np.fmax(rule_064_068_072,\n",
    "                                             np.fmax(rule_073_077_081,\n",
    "                                                     np.fmax(rule_074_078_082,\n",
    "                                                             np.fmax(rule_075_079_083,\n",
    "                                                                    np.fmax(rule_076_080_084,\n",
    "                                                                            np.fmax(rule_085_089_093,\n",
    "                                                                                    np.fmax(rule_086_090_094,                                                                                            np.fmax(rule_087_091_095,                                                                                                    np.fmax(rule_088_092_096,                                                                                                np.fmax(rule_099_103_107,                                                                                           np.fmax(rule_100_104_108,                                                                                            np.fmax(rule_109_113_117,                                                                                          np.fmax(rule_110_114_118,                                                                      np.fmax(rule_111_115_119,                                                                                        np.fmax(rule_112_116_120,                                                                                 np.fmax(rule_121_125_129,                                                                                 np.fmax(rule_122_126_130,                                                                    np.fmax(rule_123_127_131, rule_133_137_141)))))))))))))))))))))\n",
    "\n",
    "\n",
    "\n",
    "high_rules = np.fmax(rule_100_104_108,\n",
    "                    np.fmax(rule_111_115_119, \n",
    "                           np.fmax(rule_112_116_120, \n",
    "                                  np.fmax(rule_122_126_130, \n",
    "                                         np.fmax(rule_123_127_131, \n",
    "                                                np.fmax(rule_124_128_132, \n",
    "                                                       np.fmax(rule_133_137_141, \n",
    "                                                              np.fmax(rule_134_138_142, \n",
    "                                                                     np.fmax(rule_135_139_143, \n",
    "                                                                            np.fmax(rule_136_140_144))))))))))\n",
    "\n",
    "very_high_rules = np.fmax(rule_124_128_132, np.fmax(rule_135_139_143, rule_136_140_144))\n",
    "\n",
    "importance_activation_very_low = np.fmin(very_low_rules,importance_very_low)\n",
    "importance_activation_low = np.fmin(low_rules,importance_low)\n",
    "importance_activation_medium = np.fmin(medium_rules, importance_medium)\n",
    "importance_activation_high = np.fmin(high_rules, importance_high)\n",
    "importance_activation_very_high = np.fmin(very_high_rules, importance_very_high)\n",
    "importance0 = np.zeros_like(importance)\n",
    "\n",
    "fig, ax0 = plt.subplots(figsize=(8, 3))\n",
    "\n",
    "ax0.fill_between(importance, importance0, importance_activation_very_low, facecolor='b', alpha=0.7)\n",
    "ax0.plot(importance, importance_very_low, 'b', linewidth=0.5, linestyle='--', )\n",
    "ax0.fill_between(importance, importance0, importance_activation_low, facecolor='g', alpha=0.7)\n",
    "ax0.plot(importance, importance_low, 'g', linewidth=0.5, linestyle='--')\n",
    "ax0.fill_between(importance, importance0, importance_activation_medium, facecolor='r', alpha=0.7)\n",
    "ax0.plot(importance, importance_medium, 'r', linewidth=0.5, linestyle='--')\n",
    "ax0.fill_between(importance, importance0, importance_activation_high, facecolor='b', alpha=0.7)\n",
    "ax0.plot(importance, importance_high, 'b', linewidth=0.5, linestyle='--', )\n",
    "ax0.fill_between(importance, importance0, importance_activation_very_high, facecolor='g', alpha=0.7)\n",
    "ax0.plot(importance, importance_very_high, 'g', linewidth=0.5, linestyle='--')\n",
    "ax0.set_title('Output membership activity')\n",
    "\n",
    "#Defuzzification\n",
    "aggregated = np.fmax(importance_activation_very_low,np.fmax(importance_activation_low, np.fmax(importance_activation_medium,np.fmax(importance_activation_high, importance_activation_very_high))))\n",
    "importance_defuzz = fuzz.defuzz(importance, aggregated, 'centroid')\n",
    "importance_activation = fuzz.interp_membership(importance, aggregated, importance_defuzz)  # for plot\n",
    "\n",
    "# Visualize this\n",
    "fig, ax0 = plt.subplots(figsize=(8, 3))\n",
    "\n",
    "ax0.plot(importance, importance_very_low, 'b', linewidth=0.5, linestyle='--', )\n",
    "ax0.plot(importance, importance_low, 'g', linewidth=0.5, linestyle='--')\n",
    "ax0.plot(importance, importance_medium, 'r', linewidth=0.5, linestyle='--')\n",
    "ax0.plot(importance, importance_high, 'b', linewidth=0.5, linestyle='--')\n",
    "ax0.plot(importance, importance_very_high, 'g', linewidth=0.5, linestyle='--')\n",
    "ax0.fill_between(importance, importance0, aggregated, facecolor='Orange', alpha=0.7)\n",
    "ax0.plot([importance_defuzz, importance_defuzz], [0, importance_activation], 'k', linewidth=1.5, alpha=0.9)\n",
    "ax0.set_title('Aggregated membership and result (line)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "recommender.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
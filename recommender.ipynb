{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLNqYBgmGIyf"
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9hzzVAc5GBA_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy\n",
    "import json\n",
    "import nltk\n",
    "import math\n",
    "import re\n",
    "import threading\n",
    "import copy\n",
    "import requests \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize.regexp import (WordPunctTokenizer,wordpunct_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vH15YyQGM1I"
   },
   "source": [
    "Links for the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Kj91r1mXGRPD"
   },
   "outputs": [],
   "source": [
    "url_links = 'https://zrekoj.github.io/hybrid-recommender-system/dataset/links.csv'\n",
    "url_movies = 'https://zrekoj.github.io/hybrid-recommender-system/dataset/movies.csv'\n",
    "url_ratings = 'https://zrekoj.github.io/hybrid-recommender-system/dataset/ratings.csv'\n",
    "url_tags = 'https://zrekoj.github.io/hybrid-recommender-system/dataset/tags.csv'\n",
    "url_genres = 'https://zrekoj.github.io/hybrid-recommender-system/dataset/user_genre.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7uqFvueudeU"
   },
   "source": [
    "Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JUqBO0kkucLC"
   },
   "outputs": [],
   "source": [
    "ds_links = pd.read_csv(url_links, dtype = str)\n",
    "ds_movies = pd.read_csv(url_movies, dtype = str)\n",
    "ds_ratings = pd.read_csv(url_ratings)\n",
    "ds_tags = pd.read_csv(url_tags, dtype = str)\n",
    "ds_user_genres = pd.read_json(url_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uxrT24702OZK"
   },
   "outputs": [],
   "source": [
    "list_movies_id = list(ds_movies['movieId'].unique())\n",
    "list_title_id = ds_movies['title'].tolist()\n",
    "list_users_id = list(ds_ratings['userId'].unique())\n",
    "list_movies_imdbid = ds_links['imdbId'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uCHdeaAxoy5i"
   },
   "source": [
    "Input ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 572
    },
    "id": "O_MY4EUno1II",
    "outputId": "2507215a-d421-4bff-dae7-7bdce5d22934"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmovie_ids=[]\\nratings=[]\\n\\nfor i in range(10):\\n  index=random.randint(0,len(list_movies_id)-1)\\n  while list_movies_id[index] in movie_ids:\\n    index=random.randint(0,len(list_movies_id)-1)\\n  rating = float(input('Rate the movie '+str(list_title_id[index])+' from 0.5 to 5.0 or say 0.0 if you haven't seen it :'))\\n  movie_ids.append(list_movies_id[index])\\n  ratings.append(rating)\\nprint(movie_ids)\\nprint(ratings)\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "movie_ids=[]\n",
    "ratings=[]\n",
    "\n",
    "for i in range(10):\n",
    "  index=random.randint(0,len(list_movies_id)-1)\n",
    "  while list_movies_id[index] in movie_ids:\n",
    "    index=random.randint(0,len(list_movies_id)-1)\n",
    "  rating = float(input('Rate the movie '+str(list_title_id[index])+' from 0.5 to 5.0 or say 0.0 if you haven\\'t seen it :'))\n",
    "  movie_ids.append(list_movies_id[index])\n",
    "  ratings.append(rating)\n",
    "print(movie_ids)\n",
    "print(ratings)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfYUIC48Cta9"
   },
   "source": [
    "Collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zY9Fa_VcLVa"
   },
   "source": [
    "SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "szoO5K7IKg5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['Film-Noir', 'Animation', 'Musical', 'Children', 'Drama', 'War'], ['Comedy', 'Sci-Fi', 'Mystery', 'Thriller', 'Horror'])\n"
     ]
    }
   ],
   "source": [
    "def getGenresByUser(user_id, ds=ds_user_genres):\n",
    "  return ds[user_id]['like'], ds[user_id]['dislike']\n",
    "\n",
    "print(getGenresByUser(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "KRrF5bPD_bZs"
   },
   "outputs": [],
   "source": [
    "#hyperparams\n",
    "\n",
    "test_ratio = 0.2 #fraction of data to be used as test set.\n",
    "no_of_features = [8,10,12,14,17,20] # to test the performance over a different number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "HVL4pD2A9zIu"
   },
   "outputs": [],
   "source": [
    "ds_ratings['userId'] = ds_ratings['userId'].astype('str')\n",
    "ds_ratings['movieId'] = ds_ratings['movieId'].astype('str')\n",
    "\n",
    "users = ds_ratings['userId'].unique() #list of all users\n",
    "movies = ds_ratings['movieId'].unique() #list of all movies\n",
    "\n",
    "test = pd.DataFrame(columns=ds_ratings.columns)\n",
    "train = pd.DataFrame(columns=ds_ratings.columns)\n",
    "\n",
    "for u in users:\n",
    "  temp = ds_ratings[ds_ratings['userId'] == u]\n",
    "  n = len(temp)\n",
    "  test_size = int(test_ratio*n)\n",
    "\n",
    "  temp = temp.sort_values('timestamp').reset_index()\n",
    "  temp.drop('index', axis=1, inplace=True)\n",
    "\n",
    "  dummy_test = temp.loc[n-1-test_size :]\n",
    "  dummy_train = temp.loc[: n-2-test_size]\n",
    "    \n",
    "  test = pd.concat([test, dummy_test])\n",
    "  train = pd.concat([train, dummy_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GvRLP6__-98r"
   },
   "outputs": [],
   "source": [
    "from scipy.linalg import sqrtm\n",
    "\n",
    "def create_user_item_matrix(data, formatizer = {'user':0, 'item': 1, 'value': 2}):\n",
    "    itemField = formatizer['item']\n",
    "    userField = formatizer['user']\n",
    "    valueField = formatizer['value']\n",
    "\n",
    "    \n",
    "    userList = data.iloc[:,userField].tolist()\n",
    "    itemList = data.iloc[:,itemField].tolist()\n",
    "    valueList = data.iloc[:,valueField].tolist()\n",
    "\n",
    "    users = list(set(data.iloc[:,userField]))\n",
    "    items = list(set(data.iloc[:,itemField]))\n",
    "\n",
    "    users_index = {users[i]: i for i in range(len(users))}\n",
    "\n",
    "    pd_dict = {item: [np.nan for i in range(len(users))] for item in items}\n",
    "\n",
    "    for i in range(0,len(data)):\n",
    "      item = itemList[i]\n",
    "      user = userList[i]\n",
    "      value = valueList[i]\n",
    "\n",
    "      pd_dict[item][users_index[user]] = value\n",
    "    \n",
    "    X = pd.DataFrame(pd_dict)\n",
    "    X.index = users\n",
    "\n",
    "    itemcols = list(X.columns)\n",
    "    items_index = {itemcols[i]: i for i in range(len(itemcols))}\n",
    "\n",
    "    # users_index gives us a mapping of user_id to index of user\n",
    "    # items_index provides the same for items\n",
    "\n",
    "    return X, users_index, items_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "tr-QPs9A_K6a"
   },
   "outputs": [],
   "source": [
    "def svd(train, k):\n",
    "    utilMat = np.array(train)\n",
    "\n",
    "    # the nan or unavailable entries are masked\n",
    "    mask = np.isnan(utilMat)\n",
    "    masked_arr = np.ma.masked_array(utilMat, mask)\n",
    "\n",
    "    item_means = np.mean(masked_arr, axis=0)\n",
    "\n",
    "    # nan entries will replaced by the average rating for each item\n",
    "    utilMat = masked_arr.filled(item_means)\n",
    "    x = np.tile(item_means, (utilMat.shape[0],1))\n",
    "\n",
    "    # we remove the per item average from all entries.\n",
    "    # the above mentioned nan entries will be essentially zero now\n",
    "    utilMat = utilMat - x\n",
    "\n",
    "    # The magic happens here. U and V are user and item features\n",
    "    U, s, V=np.linalg.svd(utilMat, full_matrices=False)\n",
    "    s=np.diag(s)\n",
    "\n",
    "    # we take only the k most significant features\n",
    "    s=s[0:k,0:k]\n",
    "    U=U[:,0:k]\n",
    "    V=V[0:k,:]\n",
    "\n",
    "    s_root=sqrtm(s)\n",
    "    Usk=np.dot(U,s_root)\n",
    "    skV=np.dot(s_root,V)\n",
    "    UsV = np.dot(Usk, skV)\n",
    "    UsV = UsV + x\n",
    "    return UsV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3sG_ANug_Sj_"
   },
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    x = true - pred\n",
    "    return sum([xi*xi for xi in x])/len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "zalPgxeI_Wh-"
   },
   "outputs": [],
   "source": [
    "uiMat, users_index, items_index = create_user_item_matrix(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ixHyBKd3_q5f",
    "outputId": "f123df74-c648-4f27-ff56-5e9628d24459"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0037878092372208\n",
      "1.0036410576245893\n",
      "1.0047280968304313\n",
      "1.005385440971549\n",
      "1.0046710025637098\n",
      "1.0056567229647213\n"
     ]
    }
   ],
   "source": [
    "#svd evaluation\n",
    "for f in no_of_features:\n",
    "  svdout = svd(uiMat, k=f)\n",
    "  pred = [] #to store the predicted ratings\n",
    "  for _,row in test.iterrows():\n",
    "    user = row['userId']\n",
    "    item = row['movieId']\n",
    "    u_index = users_index[user]\n",
    "    \n",
    "    if item in items_index:\n",
    "      i_index = items_index[item]\n",
    "      pred_rating = svdout[u_index, i_index]\n",
    "    else:\n",
    "      pred_rating = np.mean(svdout[u_index, :])\n",
    "    pred.append(pred_rating)\n",
    "  print(rmse(test['rating'], pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "yYdr_ohfTZwz"
   },
   "outputs": [],
   "source": [
    "def filter(u_id, user_genres = ds_user_genres, item_genres = ds_movies[\"genres\"]):\n",
    "  u_likes = user_genres[u_id][\"like\"]\n",
    "  u_detest = user_genres[u_id][\"dislike\"]\n",
    "\n",
    "  useritemMat, users_index, items_index = create_user_item_matrix(ds_ratings)\n",
    "  svdout = svd(useritemMat, k=12)\n",
    "  user_pos = users_index[str(u_id)]\n",
    "  result = []\n",
    "  for i in range(len(svdout[user_pos])):\n",
    "\n",
    "    if str(i) in items_index:\n",
    "      i_id = items_index[str(i)]\n",
    "      i_genre = item_genres[i_id].split(sep=\"|\")\n",
    "\n",
    "      checkDislike =  any(item in i_genre for item in u_detest)\n",
    "      if checkDislike is False:\n",
    "        new_rate = svdout[user_pos][i]\n",
    "\n",
    "        checkLike =  any(item in i_genre for item in u_likes)\n",
    "        if checkLike is True:\n",
    "          new_rate = new_rate + 2\n",
    "        result.append([ds_movies['movieId'][i_id], ds_movies[\"title\"][i_id], new_rate])\n",
    " \n",
    "  return sorted(result, key=lambda item: item[2], reverse=True)[:20]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "e7JekM73eErX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass\n"
     ]
    }
   ],
   "source": [
    "check =  any(item in [\"Horror\", \"Comedy\"] for item in [\"Comedy\", \"Sci-Fi\", \"Mystery\", \"Thriller\"])\n",
    "if check is True:\n",
    "    print(\"pass\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ilIi5vZJbgd6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['108192',\n",
       "  \"Hotel Chevalier (Part 1 of 'The Darjeeling Limited') (2007)\",\n",
       "  7.0],\n",
       " ['2304', 'Love Is the Devil (1998)', 7.0],\n",
       " ['3173', 'Any Given Sunday (1999)', 7.0],\n",
       " ['2077', 'Journey of Natty Gann, The (1985)', 7.0],\n",
       " ['7167', 'Japanese Story (2003)', 7.0],\n",
       " ['979', 'Nothing Personal (1995)', 7.0],\n",
       " ['49', 'When Night Is Falling (1995)', 7.0],\n",
       " ['1027', 'Robin Hood: Prince of Thieves (1991)', 7.0],\n",
       " ['7054', 'Little Women (1949)', 7.0],\n",
       " ['4260', 'Visit, The (2000)', 7.0],\n",
       " ['85213', 'Sunset Limited, The (2011)', 7.0],\n",
       " ['4078', 'Amazing Grace and Chuck (1987)', 7.0],\n",
       " ['4334', 'Yi Yi (2000)', 7.0],\n",
       " ['347', 'Bitter Moon (1992)', 7.0],\n",
       " ['6886', 'Beyond Borders (2003)', 7.0],\n",
       " ['26903', 'Whisper of the Heart (Mimi wo sumaseba) (1995)', 7.0],\n",
       " ['1844', 'Live Flesh (Carne trémula) (1997)', 7.0],\n",
       " ['146', 'Amazing Panda Adventure, The (1995)', 7.0],\n",
       " ['3792', 'Duel in the Sun (1946)', 7.0],\n",
       " ['156607', \"The Huntsman Winter's War (2016)\", 7.0]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7wSplTSCq7_"
   },
   "source": [
    "**Content-based**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "INdMx6n9Cs_P"
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(u, v):\n",
    "    return np.dot(u, np.transpose(v)) / (np.linalg.norm(u) * np.linalg.norm(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJ4w4ThMbyiK"
   },
   "source": [
    "Calculate TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "jdp1gOGyb3kB"
   },
   "outputs": [],
   "source": [
    " def computeTFIDF(user_frequence_dict):\n",
    "        copied = copy.deepcopy(user_frequence_dict)\n",
    "        total_movies = len(copied)\n",
    "        total_word_movies_count = {}\n",
    "\n",
    "        for frequency in copied.values():\n",
    "            for word in frequency:\n",
    "                total_word_movies_count[word] = total_word_movies_count.get(word, 0) + 1\n",
    "\n",
    "        for frequency in copied.values():\n",
    "            total_words_count = len(frequency)\n",
    "            for word in frequency:\n",
    "                #                TF                                 IDF\n",
    "                frequency[word] = (frequency[word] / total_words_count) * (math.log(1 + (total_movies / total_word_movies_count[word])))\n",
    "        return copied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MxnJAY9xiQA2"
   },
   "source": [
    "Content-Based application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1094249 0.07950933188193429\n",
      "0119577 0.03278998241794748\n",
      "0146838 0.06455013019546886\n",
      "0089385 0.058154713046292245\n",
      "0304229 0.0855014873973386\n",
      "0114007 0.05510535815109053\n",
      "0114916 0.059594410993000585\n",
      "0102798 0.1730762940149346\n",
      "0041594 0.0705700332960813\n",
      "0199129 0.12967858576323768\n",
      "1510938 0.07786330345947903\n",
      "0092545 0.07533071561265856\n",
      "0244316 0.05788941191858763\n",
      "0104779 0.05918078229511197\n",
      "0294357 0.12049458341852527\n",
      "0113824 0.125902194245651\n",
      "0118819 0.08952145915043482\n",
      "0112342 0.09077668893012351\n",
      "0038499 0.06793468001299899\n",
      "2381991 0.06856206481457756\n",
      "[['0102798', 0.1730762940149346], ['0199129', 0.12967858576323768], ['0113824', 0.125902194245651], ['0294357', 0.12049458341852527], ['0112342', 0.09077668893012351], ['0118819', 0.08952145915043482], ['0304229', 0.0855014873973386], ['1094249', 0.07950933188193429], ['1510938', 0.07786330345947903], ['0092545', 0.07533071561265856], ['0041594', 0.0705700332960813], ['2381991', 0.06856206481457756], ['0038499', 0.06793468001299899], ['0146838', 0.06455013019546886], ['0114916', 0.059594410993000585], ['0104779', 0.05918078229511197], ['0089385', 0.058154713046292245], ['0244316', 0.05788941191858763], ['0114007', 0.05510535815109053], ['0119577', 0.03278998241794748]]\n"
     ]
    }
   ],
   "source": [
    "def content_based(user_id, hybrid=True):\n",
    "\n",
    "    movie_similarities=[]\n",
    "\n",
    "    #Get imbdIds of user movies\n",
    "    user_movies = list(\n",
    "        map(\n",
    "            lambda movie_id : str(ds_links.loc[ds_links['movieId'] == str(movie_id), 'imdbId'].values[0]), \n",
    "            ds_ratings.loc[ds_ratings['userId'] == str(user_id), 'movieId'].tolist()\n",
    "        )\n",
    "    )\n",
    "\n",
    "    #collaborative_filtering_result = filter(user_id)\n",
    "\n",
    "    collaborative_filtering_result = [['108192',\n",
    "      \"Hotel Chevalier (Part 1 of 'The Darjeeling Limited') (2007)\",\n",
    "      7.0],\n",
    "     ['2304', 'Love Is the Devil (1998)', 7.0],\n",
    "     ['3173', 'Any Given Sunday (1999)', 7.0],\n",
    "     ['2077', 'Journey of Natty Gann, The (1985)', 7.0],\n",
    "     ['7167', 'Japanese Story (2003)', 7.0],\n",
    "     ['979', 'Nothing Personal (1995)', 7.0],\n",
    "     ['49', 'When Night Is Falling (1995)', 7.0],\n",
    "     ['1027', 'Robin Hood: Prince of Thieves (1991)', 7.0],\n",
    "     ['7054', 'Little Women (1949)', 7.0],\n",
    "     ['4260', 'Visit, The (2000)', 7.0],\n",
    "     ['85213', 'Sunset Limited, The (2011)', 7.0],\n",
    "     ['4078', 'Amazing Grace and Chuck (1987)', 7.0],\n",
    "     ['4334', 'Yi Yi (2000)', 7.0],\n",
    "     ['347', 'Bitter Moon (1992)', 7.0],\n",
    "     ['6886', 'Beyond Borders (2003)', 7.0],\n",
    "     ['26903', 'Whisper of the Heart (Mimi wo sumaseba) (1995)', 7.0],\n",
    "     ['1844', 'Live Flesh (Carne trémula) (1997)', 7.0],\n",
    "     ['146', 'Amazing Panda Adventure, The (1995)', 7.0],\n",
    "     ['3792', 'Duel in the Sun (1946)', 7.0],\n",
    "     ['156607', \"The Huntsman Winter's War (2016)\", 7.0]]\n",
    "\n",
    "    movies=[]\n",
    "\n",
    "    #If we are using content-based as part of the hybrid filter, it uses the results of the collaborative filtering\n",
    "    #Otherwise it uses all movies\n",
    "    if(hybrid):\n",
    "        movies = list(\n",
    "            map(\n",
    "                lambda result : ds_links.loc[ds_links['movieId'] == str(result[0]), 'imdbId'].values[0], \n",
    "                collaborative_filtering_result\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        movies=[str(movie_id) for movie_id in list_movies_imdbid if movie_id not in user_movies]\n",
    "\n",
    "    response = requests.get('https://zrekoj.github.io/hybrid-recommender-system/user_frequency/'+ str(user_id)+'.json') \n",
    "    user_frequence_dict = response.json()\n",
    "\n",
    "    for movie in movies:\n",
    "        MaxSim = 0\n",
    "\n",
    "        movie_frequence_dict = requests.get('https://zrekoj.github.io/hybrid-recommender-system/frequency/'+ str(movie)+'.json').json() \n",
    "        user_frequence_dict[str(movie)] = movie_frequence_dict\n",
    "        TFIDF = computeTFIDF(user_frequence_dict)\n",
    "        user_frequence_dict.pop(str(movie), None)\n",
    "\n",
    "        no_exist_string = \"***###***\"\n",
    "        \n",
    "        TFIDF_highest = TFIDF[str(movie)]\n",
    "        for user_movie in user_movies:\n",
    "            TFIDF_user =  TFIDF[str(user_movie)]\n",
    "            \n",
    "            TFIDF_highest_keys = TFIDF_highest.keys()\n",
    "            TFIDF_user_keys = TFIDF_user.keys()\n",
    "            \n",
    "            coincidence = list(set(TFIDF_highest_keys) & set(TFIDF_user_keys))\n",
    "            TFIDF_highest_values_diff = list(set(TFIDF_highest_keys) - set(TFIDF_user_keys))\n",
    "            TFIDF_user_values_diff = list(set(TFIDF_user_keys) - set(TFIDF_highest_keys))\n",
    "            \n",
    "            TFIDF_highest_values = coincidence + TFIDF_highest_values_diff + ([no_exist_string] * len(TFIDF_user_values_diff))\n",
    "            TFIDF_user_values = coincidence + ([no_exist_string] * len(TFIDF_highest_values_diff)) + TFIDF_user_values_diff\n",
    "            \n",
    "            TFIDF_highest_values = list(\n",
    "                map(\n",
    "                    lambda value : TFIDF_highest[value] if value != no_exist_string else 0,\n",
    "                    TFIDF_highest_values\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            TFIDF_user_values = list(\n",
    "                map(\n",
    "                    lambda value : TFIDF_user[value] if value != no_exist_string else 0,\n",
    "                    TFIDF_user_values\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            similarity = cosine_similarity(TFIDF_highest_values, TFIDF_user_values)        \n",
    "\n",
    "            if(similarity > MaxSim):\n",
    "                MaxSim = similarity\n",
    "                \n",
    "        movie_similarities.append([movie, MaxSim])\n",
    "        \n",
    "        print(movie, MaxSim)\n",
    "\n",
    "    return sorted(movie_similarities, key=lambda item: item[1], reverse=True)\n",
    "\n",
    "print(content_based(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h66pQrMvx3oC"
   },
   "source": [
    "Fuzzy Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "id": "AooHYk2M_pY4",
    "outputId": "53624136-87cb-487c-9607-a361ea979263"
   },
   "outputs": [],
   "source": [
    "import skfuzzy as fuzz\n",
    "from skfuzzy import control as ctrl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n4V7Sd0pyT-O"
   },
   "outputs": [],
   "source": [
    "inp1 = ctrl.Antecedent(np.arange(0, 5, 1), 'average_rating')\n",
    "inp2 = ctrl.Antecedent(np.arange(0, 350, 1), 'total_ratings')\n",
    "inp3 = ctrl.Antecedent(np.arange(0, 1, 1), 'similarity')\n",
    "out = ctrl.Consequent(np.arange(0, 1, 1), 'importance')\n",
    "\n",
    "out['low'] = fuzz.trimf(out.universe, [0, 0, .2])\n",
    "out['medium'] = fuzz.trimf(out.universe, [0, .6, 25])\n",
    "out['high'] = fuzz.trimf(out.universe, [.6, 1, 25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "recommender.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

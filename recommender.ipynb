{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "recommender.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLNqYBgmGIyf"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hzzVAc5GBA_"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import random\r\n",
        "import scipy\r\n",
        "import json\r\n",
        "import nltk\r\n",
        "import math\r\n",
        "import re\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.stem.snowball import SnowballStemmer\r\n",
        "from nltk.tokenize.regexp import (WordPunctTokenizer,wordpunct_tokenize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vH15YyQGM1I"
      },
      "source": [
        "Links for the datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj91r1mXGRPD"
      },
      "source": [
        "url_links = 'https://zrekoj.github.io/hybrid-recommender-system/dataset/links.csv'\r\n",
        "url_movies = 'https://zrekoj.github.io/hybrid-recommender-system/dataset/movies.csv'\r\n",
        "url_ratings = 'https://zrekoj.github.io/hybrid-recommender-system/dataset/ratings.csv'\r\n",
        "url_tags = 'https://zrekoj.github.io/hybrid-recommender-system/dataset/tags.csv'\r\n",
        "url_genres = 'https://zrekoj.github.io/hybrid-recommender-system/dataset/user_genre.json'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7uqFvueudeU"
      },
      "source": [
        "Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUqBO0kkucLC"
      },
      "source": [
        "ds_links = pd.read_csv(url_links, dtype = str)\r\n",
        "ds_movies = pd.read_csv(url_movies, dtype = str)\r\n",
        "ds_ratings = pd.read_csv(url_ratings)\r\n",
        "ds_tags = pd.read_csv(url_tags, dtype = str)\r\n",
        "ds_user_genres = pd.read_json(url_genres)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxrT24702OZK"
      },
      "source": [
        "list_movies_id = list(ds_movies['movieId'].unique())\r\n",
        "list_title_id = ds_movies['title'].tolist()\r\n",
        "list_users_id = list(ds_ratings['userId'].unique())\r\n",
        "list_movies_imdbid = ds_links['imdbId'].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCHdeaAxoy5i"
      },
      "source": [
        "Input ratings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_MY4EUno1II",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "2507215a-d421-4bff-dae7-7bdce5d22934"
      },
      "source": [
        "movie_ids=[]\r\n",
        "ratings=[]\r\n",
        "\r\n",
        "for i in range(10):\r\n",
        "  index=random.randint(0,len(list_movies_id)-1)\r\n",
        "  while list_movies_id[index] in movie_ids:\r\n",
        "    index=random.randint(0,len(list_movies_id)-1)\r\n",
        "  rating = float(input('Rate the movie '+str(list_title_id[index])+' from 0.5 to 5.0 or say 0.0 if you haven\\'t seen it :'))\r\n",
        "  movie_ids.append(list_movies_id[index])\r\n",
        "  ratings.append(rating)\r\n",
        "print(movie_ids)\r\n",
        "print(ratings)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \"\"\"\n\u001b[0;32m--> 566\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-255a398f92c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0mlist_movies_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmovie_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_movies_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mrating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Rate the movie '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_title_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' from 0.5 to 5.0 or say 0.0 if you haven\\'t seen it :'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mmovie_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_movies_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mratings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7wSplTSCq7_"
      },
      "source": [
        "**Content-based**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INdMx6n9Cs_P"
      },
      "source": [
        "def cosine_similarity(u,v):\r\n",
        " return np.dot(u,np.transpose(v))/np.linalg.norm(u)*np.linalg.norm(v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqRoOqAubo6O"
      },
      "source": [
        "Build Frecuency Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNUIYzosbxbh"
      },
      "source": [
        "def preprocess_text(doc):\r\n",
        " stopset = set(stopwords.words('english'))\r\n",
        " stemmer = SnowballStemmer('english',ignore_stopwords=True)\r\n",
        " tokens = wordpunct_tokenize(doc)\r\n",
        " clean = [token.lower() for token in tokens if token.lower() not in stopset and len(token) > 2]\r\n",
        " stemmed_text = [stemmer.stem(word) for word in clean]\r\n",
        " return stemmed_text\r\n",
        " \r\n",
        " \r\n",
        "def create_freq_dict(movieIds, preprocessed_texts):\r\n",
        " i=0\r\n",
        " print(\"Creating frequency dictionary\")\r\n",
        " freqDict_list=[]\r\n",
        " all_tokens=set()\r\n",
        " #for j in range(0, len(preprocessed_texts)-1):\r\n",
        "   #for token in preprocessed_texts[j]:\r\n",
        "     #all_tokens.add(token)\r\n",
        " for tokens in preprocessed_texts:\r\n",
        "  freq_dict={}\r\n",
        "  \r\n",
        "  for token in tokens:\r\n",
        "    if token in freq_dict:\r\n",
        "     freq_dict[token]+=1\r\n",
        "    else:\r\n",
        "     freq_dict[token]=1\r\n",
        "  #for token in all_tokens:\r\n",
        "    #if token not in freq_dict:\r\n",
        "       #freq_dict[token]=0\r\n",
        "\r\n",
        "  temp={'term_id':i,'movie_id':movieIds[i],'freq_dict':freq_dict,'doc_length':len(tokens)}\r\n",
        "  i+=1\r\n",
        "  freqDict_list.append(temp)\r\n",
        " return freqDict_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ4w4ThMbyiK"
      },
      "source": [
        "Calculate TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdp1gOGyb3kB"
      },
      "source": [
        "def computeTF(freqDict_list):\r\n",
        " TF_scores=[]\r\n",
        " print(\"Calculating TF\")\r\n",
        " for tempDict in freqDict_list:\r\n",
        "  id=tempDict['term_id']\r\n",
        "  name=tempDict['movie_id']\r\n",
        "  for k in tempDict['freq_dict']:\r\n",
        "   temp={'term_id':id, 'movie_id':name,'TF_score':tempDict['freq_dict'][k]/tempDict['doc_length'],'key':k}\r\n",
        "   TF_scores.append(temp)\r\n",
        " return TF_scores\r\n",
        " \r\n",
        "def computeIDF(freqDict_list):\r\n",
        "  IDF_scores=[]\r\n",
        "  print(\"Calculating IDF\")\r\n",
        "  counter=-1\r\n",
        "  for dict in freqDict_list:\r\n",
        "   counter+=1\r\n",
        "   for k in dict['freq_dict'].keys():\r\n",
        "    count=sum([k in tempDict['freq_dict'] for tempDict in freqDict_list])\r\n",
        "    temp= {'term_id': counter, 'IDF_score':math.log(dict['doc_length'])/count,'key':k}\r\n",
        "    IDF_scores.append(temp)\r\n",
        "  return IDF_scores\r\n",
        " \r\n",
        "def computeTFIDF(TF_scores, IDF_scores):\r\n",
        " TF_IDF_scores=[]\r\n",
        " print(\"Calculating TF-IDF\")\r\n",
        " \r\n",
        " for j in IDF_scores:\r\n",
        "  for i in TF_scores:\r\n",
        "   if j['key']==i['key'] and j['term_id']==i['term_id']:\r\n",
        "    temp={'term_id':j['term_id'], 'movie_id':i['movie_id'], 'TFIDF_score': j['IDF_score']*i['TF_score'], 'key':i['key']}\r\n",
        "    TF_IDF_scores.append(temp)\r\n",
        " return TF_IDF_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfYUIC48Cta9"
      },
      "source": [
        "Collaborative filtering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Yf5cIo8rOe1"
      },
      "source": [
        "def readPlots(movies):\n",
        "  plots = []\n",
        "  for movie in movies:\n",
        "    url = 'https://zrekoj.github.io/hybrid-recommender-system/movies/'+ str(movie)+'.json'\n",
        "    archivo = pd.read_json(url)\n",
        "    plots.append([archivo['Plot'].tolist()[0]])\n",
        "  return plots\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HmARLkbv0CM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "outputId": "5461fc6a-aa95-4743-ab43-3be804a9e796"
      },
      "source": [
        "def createUserItemMatrix(x, y, df):\r\n",
        "  umr = np.zeros((len(y), len(x)))\r\n",
        "  for index, row in df.iterrows():\r\n",
        "    i = y.index(row['userId'])\r\n",
        "    j = x.index(row['movieId'])\r\n",
        "    umr[i, j] = row['rating']\r\n",
        "  return umr\r\n",
        "\r\n",
        "result = createUserItemMatrix(list_movies_id, list_users_id, ds_ratings)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-a8ddfd2b5efa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mumr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreateUserItemMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_movies_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_users_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_ratings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-33-a8ddfd2b5efa>\u001b[0m in \u001b[0;36mcreateUserItemMatrix\u001b[0;34m(x, y, df)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'userId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'movieId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mumr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mumr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 1.0 is not in list"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UZ151ZS2Il7"
      },
      "source": [
        "def getUmrRating(user_id, movie_id, umr, list_users_id=list_users_id, list_movies_id=list_movies_id):\r\n",
        "  return umr[list_users_id.index(user_id), list_movies_id.index(movie_id)]\r\n",
        "\r\n",
        "print(getUmrRating(1, 101, result))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3_uQbM_VWTo"
      },
      "source": [
        "print(list_users_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zY9Fa_VcLVa"
      },
      "source": [
        "SVD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szoO5K7IKg5e"
      },
      "source": [
        "def getGenresByUser(user_id, ds=ds_user_genres):\r\n",
        "  return ds[user_id]['like'], ds[user_id]['dislike']\r\n",
        "\r\n",
        "print(getGenresByUser(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRrF5bPD_bZs"
      },
      "source": [
        "#hyperparams\r\n",
        "\r\n",
        "test_ratio = 0.2 #fraction of data to be used as test set.\r\n",
        "no_of_features = [8,10,12,14,17,20] # to test the performance over a different number of features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVL4pD2A9zIu"
      },
      "source": [
        "ds_ratings['userId'] = ds_ratings['userId'].astype('str')\r\n",
        "ds_ratings['movieId'] = ds_ratings['movieId'].astype('str')\r\n",
        "\r\n",
        "users = ds_ratings['userId'].unique() #list of all users\r\n",
        "movies = ds_ratings['movieId'].unique() #list of all movies\r\n",
        "\r\n",
        "test = pd.DataFrame(columns=ds_ratings.columns)\r\n",
        "train = pd.DataFrame(columns=ds_ratings.columns)\r\n",
        "\r\n",
        "for u in users:\r\n",
        "  temp = ds_ratings[ds_ratings['userId'] == u]\r\n",
        "  n = len(temp)\r\n",
        "  test_size = int(test_ratio*n)\r\n",
        "\r\n",
        "  temp = temp.sort_values('timestamp').reset_index()\r\n",
        "  temp.drop('index', axis=1, inplace=True)\r\n",
        "\r\n",
        "  dummy_test = temp.loc[n-1-test_size :]\r\n",
        "  dummy_train = temp.loc[: n-2-test_size]\r\n",
        "    \r\n",
        "  test = pd.concat([test, dummy_test])\r\n",
        "  train = pd.concat([train, dummy_train])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvRLP6__-98r"
      },
      "source": [
        "from scipy.linalg import sqrtm\r\n",
        "\r\n",
        "def create_user_item_matrix(data, formatizer = {'user':0, 'item': 1, 'value': 2}):\r\n",
        "    itemField = formatizer['item']\r\n",
        "    userField = formatizer['user']\r\n",
        "    valueField = formatizer['value']\r\n",
        "\r\n",
        "    \r\n",
        "    userList = data.iloc[:,userField].tolist()\r\n",
        "    itemList = data.iloc[:,itemField].tolist()\r\n",
        "    valueList = data.iloc[:,valueField].tolist()\r\n",
        "\r\n",
        "    users = list(set(data.iloc[:,userField]))\r\n",
        "    items = list(set(data.iloc[:,itemField]))\r\n",
        "\r\n",
        "    users_index = {users[i]: i for i in range(len(users))}\r\n",
        "\r\n",
        "    pd_dict = {item: [np.nan for i in range(len(users))] for item in items}\r\n",
        "\r\n",
        "    for i in range(0,len(data)):\r\n",
        "      item = itemList[i]\r\n",
        "      user = userList[i]\r\n",
        "      value = valueList[i]\r\n",
        "\r\n",
        "      pd_dict[item][users_index[user]] = value\r\n",
        "    \r\n",
        "    X = pd.DataFrame(pd_dict)\r\n",
        "    X.index = users\r\n",
        "\r\n",
        "    itemcols = list(X.columns)\r\n",
        "    items_index = {itemcols[i]: i for i in range(len(itemcols))}\r\n",
        "\r\n",
        "    # users_index gives us a mapping of user_id to index of user\r\n",
        "    # items_index provides the same for items\r\n",
        "\r\n",
        "    return X, users_index, items_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr-QPs9A_K6a"
      },
      "source": [
        "def svd(train, k):\r\n",
        "    utilMat = np.array(train)\r\n",
        "\r\n",
        "    # the nan or unavailable entries are masked\r\n",
        "    mask = np.isnan(utilMat)\r\n",
        "    masked_arr = np.ma.masked_array(utilMat, mask)\r\n",
        "\r\n",
        "    item_means = np.mean(masked_arr, axis=0)\r\n",
        "\r\n",
        "    # nan entries will replaced by the average rating for each item\r\n",
        "    utilMat = masked_arr.filled(item_means)\r\n",
        "    x = np.tile(item_means, (utilMat.shape[0],1))\r\n",
        "\r\n",
        "    # we remove the per item average from all entries.\r\n",
        "    # the above mentioned nan entries will be essentially zero now\r\n",
        "    utilMat = utilMat - x\r\n",
        "\r\n",
        "    # The magic happens here. U and V are user and item features\r\n",
        "    U, s, V=np.linalg.svd(utilMat, full_matrices=False)\r\n",
        "    s=np.diag(s)\r\n",
        "\r\n",
        "    # we take only the k most significant features\r\n",
        "    s=s[0:k,0:k]\r\n",
        "    U=U[:,0:k]\r\n",
        "    V=V[0:k,:]\r\n",
        "\r\n",
        "    s_root=sqrtm(s)\r\n",
        "    Usk=np.dot(U,s_root)\r\n",
        "    skV=np.dot(s_root,V)\r\n",
        "    UsV = np.dot(Usk, skV)\r\n",
        "    UsV = UsV + x\r\n",
        "    return UsV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sG_ANug_Sj_"
      },
      "source": [
        "def rmse(true, pred):\r\n",
        "    x = true - pred\r\n",
        "    return sum([xi*xi for xi in x])/len(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zalPgxeI_Wh-"
      },
      "source": [
        "uiMat, users_index, items_index = create_user_item_matrix(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixHyBKd3_q5f",
        "outputId": "f123df74-c648-4f27-ff56-5e9628d24459"
      },
      "source": [
        "#svd evaluation\r\n",
        "for f in no_of_features:\r\n",
        "  svdout = svd(uiMat, k=f)\r\n",
        "  pred = [] #to store the predicted ratings\r\n",
        "  for _,row in test.iterrows():\r\n",
        "    user = row['userId']\r\n",
        "    item = row['movieId']\r\n",
        "    u_index = users_index[user]\r\n",
        "    \r\n",
        "    if item in items_index:\r\n",
        "      i_index = items_index[item]\r\n",
        "      pred_rating = svdout[u_index, i_index]\r\n",
        "    else:\r\n",
        "      pred_rating = np.mean(svdout[u_index, :])\r\n",
        "    pred.append(pred_rating)\r\n",
        "  print(rmse(test['rating'], pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0037878092372214\n",
            "1.0036410576245889\n",
            "1.0047280968304313\n",
            "1.0053854409715486\n",
            "1.0046710025637098\n",
            "1.0056567229647213\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYdr_ohfTZwz"
      },
      "source": [
        "def filter(u_id, user_genres = ds_user_genres, item_genres = ds_movies[\"genres\"]):\r\n",
        "  u_likes = user_genres[u_id][\"like\"]\r\n",
        "  u_detest = user_genres[u_id][\"dislike\"]\r\n",
        "\r\n",
        "  useritemMat, users_index, items_index = create_user_item_matrix(ds_ratings)\r\n",
        "  svdout = svd(useritemMat, k=12)\r\n",
        "  user_pos = users_index[str(u_id)]\r\n",
        "  result = []\r\n",
        "  for i in range(len(svdout[user_pos])):\r\n",
        "\r\n",
        "    if str(i) in items_index:\r\n",
        "      i_id = items_index[str(i)]\r\n",
        "      i_genre = item_genres[i_id].split(sep=\"|\")\r\n",
        "\r\n",
        "      checkDislike =  any(item in i_genre for item in u_detest)\r\n",
        "      if checkDislike is False:\r\n",
        "        new_rate = svdout[user_pos][i]\r\n",
        "\r\n",
        "        checkLike =  any(item in i_genre for item in u_likes)\r\n",
        "        if checkLike is True:\r\n",
        "          new_rate = new_rate + 2\r\n",
        "        result.append([i_id, ds_movies[\"title\"][i_id], new_rate])\r\n",
        " \r\n",
        "  return sorted(result, key=lambda item: item[2], reverse=True)[:20]\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrHeVCZqcNjw"
      },
      "source": [
        "print(ds_user_genres)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7JekM73eErX"
      },
      "source": [
        "check =  any(item in [\"Horror\", \"Comedy\"] for item in [\"Comedy\", \"Sci-Fi\", \"Mystery\", \"Thriller\"])\r\n",
        "if check is True:\r\n",
        "    print(\"pass\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilIi5vZJbgd6"
      },
      "source": [
        "filter(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxnJAY9xiQA2"
      },
      "source": [
        "Content-Based application"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFknV71aVRK6",
        "outputId": "b03ae66a-e902-4c96-a2f9-69d1ec9d4ac0"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvvBWUOud1mz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d63f055f-3fd0-4e4a-979c-be80feee7849"
      },
      "source": [
        "def content_based(user_id, hybrid=True):\r\n",
        "\r\n",
        "  movie_similarities=[]\r\n",
        "  temp_user_movies=[]\r\n",
        "  temp_movies=[]\r\n",
        "  user_movies=[]\r\n",
        "  #Get movies of selected user\r\n",
        "  for k in range(0,len(ds_ratings)-1):\r\n",
        "    if str(ds_ratings['userId'][k])==str(user_id):\r\n",
        "      temp_user_movies.append(ds_ratings['movieId'][k])\r\n",
        "  #Get imbdIds of user movies\r\n",
        "  for k in range(0,len(ds_links)-1):\r\n",
        "    if str(ds_links['movieId'][k]) in temp_user_movies:\r\n",
        "      user_movies.append(str(ds_links['imdbId'][k]))\r\n",
        "  \r\n",
        "  movies=[]\r\n",
        "  \r\n",
        "  #If we are using content-based as part of the hybrid filter, it uses the results of the collaborative filtering\r\n",
        "  #Otherwise it uses all movies\r\n",
        "  if(hybrid):\r\n",
        "    temp_movies=[str(x[0]) for x in filter(user_id)]\r\n",
        "    for k in range(0,len(ds_links)):\r\n",
        "      if str(ds_links['movieId'][k]) in temp_movies:\r\n",
        "        movies.append(str(ds_links['imdbId'][k]))\r\n",
        "  else:\r\n",
        "    movies=[str(movie_id) for movie_id in list_movies_imdbid if movie_id not in user_movies]\r\n",
        "  #Preprocess user movies\r\n",
        "  preprocessed_texts=[preprocess_text(text[0]) for text in readPlots(user_movies)]\r\n",
        "\r\n",
        "  for i in range(0,len(movies)-1):\r\n",
        "    MaxSim=0\r\n",
        "    user_movies.append(movies[i])\r\n",
        "    preprocessed_texts.append(preprocess_text(readPlots([movies[i]])[0][0]))\r\n",
        "    freqDict=create_freq_dict(user_movies, preprocessed_texts)\r\n",
        "    user_movies.pop(-1)\r\n",
        "    preprocessed_texts.pop(-1)\r\n",
        "    TFIDF=computeTFIDF(computeTF(freqDict),computeIDF(freqDict))\r\n",
        "\r\n",
        "    TFIDF_highest_temp=[[y[\"key\"],y[\"TFIDF_score\"]] for y in TFIDF if y[\"movie_id\"]==movies[i]]\r\n",
        "    TFIDF_highest=[y[1] for y in TFIDF_highest_temp]\r\n",
        "    #TFIDF_highest=list(map(lambda y : y[\"TFIDF_score\"] if y[\"movie_id\"]==movies[i] else 0, TFIDF))\r\n",
        "    \r\n",
        "    for j in range(0,9):\r\n",
        "      \r\n",
        "      TFIDF_user_temp={x[\"key\"]:x[\"TFIDF_score\"] for x in TFIDF if x[\"movie_id\"]==user_movies[j]}\r\n",
        "      TFIDF_user=[]\r\n",
        "      for x in TFIDF_highest_temp:\r\n",
        "        if x[0] in TFIDF_user_temp.keys():\r\n",
        "          TFIDF_user.append(TFIDF_user_temp[x[0]])\r\n",
        "        else:\r\n",
        "          TFIDF_user.append(0)\r\n",
        "\r\n",
        "      #TFIDF_user=list(map(lambda y : y[\"TFIDF_score\"] if y[\"movie_id\"]==user_movies[i] else 0, TFIDF))\r\n",
        "      \r\n",
        "      similarity=cosine_similarity(TFIDF_highest,TFIDF_user)\r\n",
        "      if(similarity>MaxSim):\r\n",
        "        MaxSim=similarity\r\n",
        "    movie_similarities.append([movies[i],MaxSim])\r\n",
        "  return sorted(movie_similarities, key=lambda item: item[1], reverse=True)\r\n",
        "\r\n",
        "print(content_based(1))\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h66pQrMvx3oC"
      },
      "source": [
        "Fuzzy Expert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AooHYk2M_pY4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "53624136-87cb-487c-9607-a361ea979263"
      },
      "source": [
        "import skfuzzy as fuzz\r\n",
        "from skfuzzy import control as ctrl\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-54adb2e1f13c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mskfuzzy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfuzz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskfuzzy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontrol\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'skfuzzy'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4V7Sd0pyT-O"
      },
      "source": [
        "inp1 = ctrl.Antecedent(np.arange(0, 5, 1), 'average_rating')\r\n",
        "inp2 = ctrl.Antecedent(np.arange(0, 350, 1), 'total_ratings')\r\n",
        "inp3 = ctrl.Antecedent(np.arange(0, 1, 1), 'similarity')\r\n",
        "out = ctrl.Consequent(np.arange(0, 1, 1), 'importance')\r\n",
        "\r\n",
        "out['low'] = fuzz.trimf(out.universe, [0, 0, .2])\r\n",
        "out['medium'] = fuzz.trimf(out.universe, [0, .6, 25])\r\n",
        "out['high'] = fuzz.trimf(out.universe, [.6, 1, 25])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
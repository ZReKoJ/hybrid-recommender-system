import pandas as pd
import numpy as np
import random
import scipy
import json
import nltk
import math
import re
import threading
from nltk.corpus import stopwords
from nltk.stem.snowball import SnowballStemmer
from nltk.tokenize.regexp import (WordPunctTokenizer,wordpunct_tokenize)
import time

user_movies = ['0114709', '0113228', '0113277', '0114369', '0114814', '0116367', '0115734', '0112573', '0114287', '0109370', '0112851', '0112508', '0109445', '0109686', '0109707', '0076759', '0110912', '0111282', '0114694', '0109444', '0109830', '0110213', '0110475', '0109303', '0106677', '0106977', '0107290', '0107614', '0108052', '0108174', '0108333', '0108358', '0099348', '0096895', '0102926', '0032910', '0116282', '0117060', '0116683', '0117705', '0117500', '0117998', '0116629', '0117628', '0032138', '0033467', '0029843', '0039420', '0031679', '0072951', '0063819', '0038166', '0057546', '0033563', '0076538', '0066817', '0043274', '0117887', '0116409', '0117802', '0067992', '0079470', '0105236', '0091763', '0103772', '0083866', '0096754', '0071853', '0080684', '0093779', '0082971', '0066921', '0078788', '0086190', '0099685', '0078748', '0054215', '0080455', '0093058', '0097499', '0045061', '0088247', '0023969', '0081505', '0107048', '0088763', '0091203', '0072431', '0032455', '0097576', '0084503', '0013442', '0103776', '0105435', '0104691', '0119640', '0118702', '0119229', '0118655', '0118880', '0119094', '0119654', '0082198', '0119488', '0119468', '0119174', '0119345', '0120201', '0118715', '0120888', '0120491', '0120769', '0120890', '0122718', '0020629', '0075148', '0091369', '0093409', '0089218', '0099088', '0034492', '0120815', '0088814', '0091059', '0091149', '0097523', '0120768', '0061852', '0076618', '0089908', '0102803', '0053285', '0038969', '0084827', '0087469', '0077869', '0070016', '0084649', '0090633', '0089469', '0088323', '0094721', '0096446', '0105629', '0104257', '0120812', '0099487', '0120586', '0130018', '0120660', '0024216', '0124198', '0155975', '0128445', '0088011', '0090357', '0120863', '0091225', '0072271', '0090555', '0092086', '0138987', '0151804', '0074812', '0063442', '0120735', '0133093', '0139239', '0133189', '0099422', '0120616', '0120915', '0078346', '0081573', '0021814', '0021884', '0034398', '0073629', '0130827', '0158983', '0087332', '0129167', '0094737', '0120657', '0169547', '0082348', '0031397', '0100802', '0061578', '0058150', '0057076', '0055928', '0137523', '0093870', '0096438', '0070328', '0059800', '0120601', '0094012', '0070608', '0120655', '0151137', '0056197', '0120689', '0064276', '0134119', '0104187', '0105417', '0105793', '0134084', '0102138', '0103060', '0108308', '0087985', '0093105', '0107050', '0089457', '0102057', '0093773', '0172495', '0215129', '0071807', '0071230', '0079501', '0082694', '0067741', '0090728', '0162650', '0120903', '0103241', '0092106', '0066026']

def readPlot(movie_id):
    url = 'https://zrekoj.github.io/hybrid-recommender-system/movies/'+ str(movie_id)+'.json'
    archivo = pd.read_json(url)
    return archivo['Plot'].tolist()[0]

def preprocessText(movie_id):
    doc = readPlot(movie_id)
    stopset = set(stopwords.words('english'))
    stemmer = SnowballStemmer('english',ignore_stopwords=True)
    tokens = wordpunct_tokenize(doc)
    clean = [token.lower() for token in tokens if token.lower() not in stopset and len(token) > 2]
    stemmed_text = [stemmer.stem(word) for word in clean]
    return stemmed_text

def readPlots(movies):
    threads = list()
    processed = []
    for index, m in enumerate(movies):
        # Open threads
        x = threading.Thread(target=lambda p, arg: p.append(preprocessText(arg)), args=(processed, m))
        threads.append(x)
        x.start()
    
    count = 0
    for index, thread in enumerate(threads):
        thread.join()
        count = count + 1
        print("Processed", str(count) + "/" + str(len(threads)))
        
    return processed
        
a = readPlots(user_movies)

print(a)